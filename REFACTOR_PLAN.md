# CloudLink Architecture Refactoring Plan

## ğŸ¯ Objective
Transition the project from a monolithic "Google Drive Wrapper" to a modular, extensible **Storage Provider Architecture**.
The goal is to decouple the core business logic (Upload/Download/Auth) from the specific storage implementation (Google Drive), enabling future support for OneDrive, S3, WebDAV, etc., with minimal friction.

## ğŸ— Proposed Directory Structure

```text
src/
â”œâ”€â”€ index.js                     # Entry point (Router & Dependency Injection)
â”œâ”€â”€ config.js                    # Centralized configuration (Env vars parsing)
â”œâ”€â”€ core/                        # Business Logic Layer (Storage Agnostic)
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â””â”€â”€ auth-manager.js      # JWT & Password logic
â”‚   â”œâ”€â”€ handlers/                # Request Handlers
â”‚   â”‚   â”œâ”€â”€ upload.js            # Standard upload handler
â”‚   â”‚   â”œâ”€â”€ chunked-upload.js    # Chunked upload session logic
â”‚   â”‚   â”œâ”€â”€ download.js          # Download redirect/proxy logic
â”‚   â”‚   â””â”€â”€ admin.js             # Admin API logic
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ rate-limiter.js
â”‚       â””â”€â”€ helpers.js
â””â”€â”€ storage/                     # Storage Layer (The Interface)
    â”œâ”€â”€ provider-interface.js    # JSDoc definition of the Abstract Interface
    â”œâ”€â”€ factory.js               # StorageProviderFactory (Selects provider based on config)
    â””â”€â”€ providers/               # Concrete Implementations
        â””â”€â”€ google-drive/
            â”œâ”€â”€ index.js         # The Provider Class (Implements Interface)
            â””â”€â”€ api-client.js    # Raw Google API calls (The old google-drive-api.js)
```

## ğŸ§© Interface Definition (`IStorageProvider`)

Every storage provider must implement the following methods. This contract ensures the `core/handlers` never need to know *which* cloud is being used.

```javascript
/**
 * @interface IStorageProvider
 */
class IStorageProvider {
  /**
   * Initialize the provider (e.g., fetch access tokens).
   * @returns {Promise<void>}
   */
  async init() {}

  /**
   * List files in the storage.
   * @param {object} options - { limit, pageToken, search, type }
   * @returns {Promise<{ files: Array, nextPageToken: string }>}
   */
  async listFiles(options) {}

  /**
   * Upload a small file directly.
   * @param {File|Blob} file 
   * @param {string} fileName 
   * @returns {Promise<{ id: string, name: string, size: number }>}
   */
  async uploadFile(file, fileName) {}

  /**
   * Start a resumable upload session (for large files).
   * @param {string} fileName 
   * @param {number} fileSize 
   * @returns {Promise<string>} - The upload URL (or session identifier)
   */
  async createUploadSession(fileName, fileSize) {}

  /**
   * Upload a single chunk to the session.
   * @param {string} sessionUrl - The URL returned by createUploadSession
   * @param {ArrayBuffer} chunkData 
   * @param {number} startByte 
   * @param {number} totalSize 
   * @returns {Promise<{ completed: boolean, id?: string, nextStart?: number }>}
   */
  async uploadChunk(sessionUrl, chunkData, startByte, totalSize) {}

  /**
   * Check the status of an upload session.
   * @param {string} sessionUrl 
   * @param {number} totalSize 
   * @returns {Promise<{ completed: boolean, bytesUploaded: number }>}
   */
  async checkUploadStatus(sessionUrl, totalSize) {}

  /**
   * Get a downloadable stream/response.
   * @param {string} fileId 
   * @returns {Promise<Response>}
   */
  async downloadFile(fileId) {}

  /**
   * Delete a file.
   * @param {string} fileId 
   * @returns {Promise<boolean>}
   */
  async deleteFile(fileId) {}
}
```

## ğŸš€ Execution Steps

### Phase 1: Preparation
1.  **Backup**: Ensure the current working version is committed to Git.
2.  **Create Directories**: Set up the new folder structure.

### Phase 2: Migration (The "Lift and Shift")
1.  **Move Utils**: Move `utils.js` -> `src/core/utils/helpers.js` and `rate-limiter.js` -> `src/core/utils/rate-limiter.js`.
2.  **Move Auth**: Move `auth-manager.js` -> `src/core/auth/auth-manager.js`.
3.  **Refactor Google Drive API**:
    *   Rename `src/google-drive-api.js` to `src/storage/providers/google-drive/api-client.js`.
    *   Create `src/storage/providers/google-drive/index.js` which imports `api-client.js` and maps its methods to the `IStorageProvider` interface names.

### Phase 3: Handler Updates
1.  **Refactor Handlers**: Update `upload-handler.js`, `chunked-upload-handler.js`, etc. to import from `../storage/factory.js` (or accept the provider as an argument) instead of importing `GoogleDriveAPI` directly.
2.  **Dependency Injection**: In `src/index.js`, initialize the provider once:
    ```javascript
    const storageProvider = StorageFactory.create(env);
    await storageProvider.init(); // cache instance across requests when possible
    // Pass storageProvider to handlers
    return handleUpload(request, env, storageProvider);
    ```

### Phase 4: Verification
1.  **Run Tests**: Verify that file uploads (small & large), downloads, and listing still work exactly as before.
2.  **Linting**: Ensure no circular dependencies or missing imports.

## ğŸ”® Future Benefits
-   **Add OneDrive**: Create `src/storage/providers/onedrive/index.js`.
-   **Add S3**: Create `src/storage/providers/s3/index.js`.
-   **Local Dev**: Create `src/storage/providers/mock/index.js` to develop without needing internet or API keys.
